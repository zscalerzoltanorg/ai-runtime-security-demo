# --- Minimal local defaults (works out of the box for Ollama + bundled MCP) ---
PORT=5050
APP_DEMO_NAME=AI App Demo

# Local Ollama runtime
OLLAMA_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.2:1b

# Bundled local MCP server is auto-used when MCP_SERVER_COMMAND is empty
MCP_SERVER_COMMAND=
MCP_TIMEOUT_SECONDS=15
MCP_PROTOCOL_VERSION=2024-11-05

# Safe defaults for local agent/tool loops
AGENTIC_MAX_STEPS=3
MULTI_AGENT_MAX_SPECIALIST_ROUNDS=1
BRAVE_SEARCH_MAX_RESULTS=5

# --- Optional provider/API settings (leave blank until you need them) ---
ANTHROPIC_API_KEY=
OPENAI_API_KEY=
PERPLEXITY_API_KEY=
XAI_API_KEY=
GEMINI_API_KEY=
VERTEX_PROJECT_ID=
AZURE_AI_FOUNDRY_API_KEY=
AZURE_AI_FOUNDRY_BASE_URL=
LITELLM_API_KEY=
LITELLM_BASE_URL=
AWS_REGION=
BEDROCK_AGENT_ID=
BEDROCK_AGENT_ALIAS_ID=

# Optional model overrides (normally set in UI settings when needed)
ANTHROPIC_MODEL=
OPENAI_MODEL=
PERPLEXITY_MODEL=
XAI_MODEL=
GEMINI_MODEL=
VERTEX_MODEL=
VERTEX_LOCATION=
LITELLM_MODEL=
BEDROCK_INVOKE_MODEL=
AZURE_AI_FOUNDRY_MODEL=

# Zscaler AI Guard DAS/API
ZS_GUARDRAILS_API_KEY=
ZS_GUARDRAILS_URL=https://api.zseclipse.net/v1/detection/resolve-and-execute-policy
ZS_GUARDRAILS_TIMEOUT_SECONDS=15
ZS_GUARDRAILS_CONVERSATION_ID_HEADER_NAME=conversationIdHeaderName

# Zscaler AI Guard Proxy mode
ZS_PROXY_BASE_URL=https://proxy.zseclipse.net
ZS_PROXY_API_KEY_HEADER_NAME=X-ApiKey
ZS_PROXY_API_KEY=
ANTHROPIC_ZS_PROXY_API_KEY=
OPENAI_ZS_PROXY_API_KEY=

# Optional corp TLS override (only if your local network requires it)
SSL_CERT_FILE=
REQUESTS_CA_BUNDLE=
